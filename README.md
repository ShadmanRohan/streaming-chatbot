# ChatServer â€” RAG-Powered Chatbot Backend

Django 5 backend with document ingestion, semantic search (with MMR), and chat capabilities.

## Features

- ğŸ“„ **Document Management**: Upload and process text documents
- ğŸ” **Semantic Search**: SBERT embeddings with cosine similarity
- ğŸ¯ **MMR (Maximal Marginal Relevance)**: Diverse, relevant retrieval results
- ğŸ’¬ **Chat Sessions**: Conversation management with message history
- ğŸ§ª **Comprehensive Tests**: Unit tests for all retrieval functions

---

## Quick Start

### 1. Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Or use conda environment
conda activate legal_assistant
pip install -r requirements.txt

# Run migrations
python manage.py migrate

# Create superuser (for admin access)
python manage.py createsuperuser
```

### 2. Run Server

```bash
python manage.py runserver
```

### 3. Health Check

```bash
curl http://localhost:8000/health/
# {"status": "ok"}
```

---

## API Endpoints

### Health

#### GET `/health/`
Health check endpoint.

```bash
curl http://localhost:8000/health/
```

**Response:**
```json
{
  "status": "ok"
}
```

---

### Documents

#### POST `/api/documents/upload/`
Upload and process a document.

```bash
curl -X POST http://localhost:8000/api/documents/upload/ \
  -F "file=@document.txt" \
  -F "auto_process=true"
```

**Response:**
```json
{
  "id": "uuid-here",
  "filename": "document.txt",
  "chunk_count": 5,
  "auto_processed": true,
  "created_at": "2025-10-08T12:00:00Z"
}
```

#### GET `/api/documents/`
List all documents.

```bash
curl http://localhost:8000/api/documents/
```

**Response:**
```json
[
  {
    "id": "uuid",
    "filename": "document.txt",
    "raw_text": "Full document text...",
    "chunk_count": 5,
    "created_at": "2025-10-08T12:00:00Z"
  }
]
```

#### GET `/api/documents/{id}/`
Get a specific document.

```bash
curl http://localhost:8000/api/documents/{document-id}/
```

#### GET `/api/documents/{id}/chunks/`
Get all chunks for a document.

```bash
curl http://localhost:8000/api/documents/{document-id}/chunks/
```

**Response:**
```json
[
  {
    "id": "chunk-uuid",
    "chunk_index": 0,
    "text": "This is chunk text...",
    "has_embedding": true,
    "created_at": "2025-10-08T12:00:00Z"
  }
]
```

---

### Retrieval (Semantic Search)

#### POST `/api/retrieve/`
Search for relevant document chunks using semantic similarity.

**With MMR (recommended for diversity):**
```bash
curl -X POST http://localhost:8000/api/retrieve/ \
  -H "Content-Type: application/json" \
  -d '{
    "query": "machine learning algorithms",
    "top_k": 5,
    "use_mmr": true,
    "lambda_param": 0.5
  }'
```

**Without MMR (pure relevance):**
```bash
curl -X POST http://localhost:8000/api/retrieve/ \
  -H "Content-Type: application/json" \
  -d '{
    "query": "machine learning",
    "top_k": 3,
    "use_mmr": false
  }'
```

**Filter by document:**
```bash
curl -X POST http://localhost:8000/api/retrieve/ \
  -H "Content-Type: application/json" \
  -d '{
    "query": "search text",
    "top_k": 5,
    "document_ids": ["doc-uuid-1", "doc-uuid-2"]
  }'
```

**Parameters:**
- `query` (required): Search query text
- `top_k` (optional, default: 3): Number of results to return
- `use_mmr` (optional, default: true): Enable MMR for diversity
- `lambda_param` (optional, default: 0.5): MMR trade-off (0=diversity, 1=relevance)
- `document_ids` (optional): Filter by specific document IDs

**Response:**
```json
{
  "query": "machine learning",
  "top_k": 3,
  "use_mmr": true,
  "lambda_param": 0.5,
  "results": [
    {
      "score": 0.8532,
      "chunk_id": "chunk-uuid",
      "text": "Machine learning is a subset of AI...",
      "document_id": "doc-uuid",
      "document_filename": "ml-basics.txt",
      "chunk_index": 2
    }
  ]
}
```

---

### Chat Sessions

#### GET `/api/sessions/`
List all chat sessions.

```bash
curl http://localhost:8000/api/sessions/
```

#### POST `/api/sessions/`
Create a new chat session.

```bash
curl -X POST http://localhost:8000/api/sessions/ \
  -H "Content-Type: application/json" \
  -d '{"title": "New Conversation"}'
```

#### GET `/api/sessions/{id}/`
Get a specific session with messages.

```bash
curl http://localhost:8000/api/sessions/{session-id}/
```

---

## Management Commands

### Ingest Documents
Process all documents (chunk + embed) in bulk:

```bash
python manage.py ingest_docs
```

This will:
1. Find all documents without embeddings
2. Chunk the text
3. Generate embeddings using SBERT
4. Store in database

---

## Configuration

### Environment Variables

Create a `.env` file (see `.env.example`):

```bash
# Django
SECRET_KEY=your-secret-key
DEBUG=1
ALLOWED_HOSTS=localhost,127.0.0.1

# Database (optional - defaults to SQLite)
DB_NAME=qsl_chatbot
DB_USER=qsl_user
DB_PASSWORD=qsl_pass
DB_HOST=localhost
DB_PORT=5432

# OpenAI (for future use)
OPENAI_API_KEY=sk-...
```

### Database

**SQLite (default):**
- Auto-configured, works out of the box
- Uses `db.sqlite3` file

**PostgreSQL (optional):**
- Set `DB_NAME` env var to enable
- Requires `psycopg2-binary` (already in requirements)
- For pgvector support, install extension in Postgres

---

## Testing

### Run All Tests
```bash
python manage.py test
```

### Run Specific Tests
```bash
# Test retrieval functions
python manage.py test chat.tests.RetrievalTests

# Test MMR algorithm
python manage.py test chat.tests.MMRTests

# Test chunking
python manage.py test chat.tests.ChunkingTests
```

### Test Coverage
- âœ… Document chunking
- âœ… MMR algorithm (with/without diversity)
- âœ… Semantic search (with/without MMR)
- âœ… Document filtering
- âœ… Edge cases (empty corpus, no embeddings)

---

## Architecture

### Components

1. **Document Management** (`chat/models.py`)
   - `Document`: Raw text storage
   - `DocumentChunk`: Text chunks with embeddings

2. **Chunking** (`chat/chunking.py`)
   - Semantic paragraph-based splitting
   - Configurable max length

3. **Embeddings** (`chat/embedding_utils.py`)
   - SBERT model: `all-MiniLM-L6-v2`
   - 384-dimensional vectors
   - Cosine similarity

4. **Retrieval** (`chat/retrieval.py`)
   - Basic similarity search
   - MMR for diversity
   - Document filtering

5. **Chat** (`chat/models.py`)
   - `ChatSession`: Conversation container
   - `ChatMessage`: User/assistant messages

---

## Tech Stack

- **Framework**: Django 5.0.6
- **API**: Django REST Framework 3.15
- **Embeddings**: sentence-transformers (SBERT)
- **Database**: SQLite (default) / PostgreSQL (optional)
- **Python**: 3.10+

---

## Project Structure

```
chatserver/
â”œâ”€â”€ chat/                    # Main app
â”‚   â”œâ”€â”€ models.py           # Database models
â”‚   â”œâ”€â”€ serializers.py      # DRF serializers
â”‚   â”œâ”€â”€ views.py            # API endpoints
â”‚   â”œâ”€â”€ urls.py             # URL routing
â”‚   â”œâ”€â”€ retrieval.py        # Search & MMR
â”‚   â”œâ”€â”€ embedding_utils.py  # Embedding generation
â”‚   â”œâ”€â”€ chunking.py         # Text chunking
â”‚   â”œâ”€â”€ tests.py            # Unit tests
â”‚   â””â”€â”€ management/
â”‚       â””â”€â”€ commands/
â”‚           â””â”€â”€ ingest_docs.py
â”œâ”€â”€ chatserver/             # Project settings
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ manage.py
â””â”€â”€ README.md
```

---

## Development

### Add New Document
```bash
# Via API
curl -X POST http://localhost:8000/api/documents/upload/ \
  -F "file=@mydoc.txt"

# Via admin
# Go to http://localhost:8000/admin/chat/document/
```

### Test Retrieval
```bash
# Search across all documents
curl -X POST http://localhost:8000/api/retrieve/ \
  -H "Content-Type: application/json" \
  -d '{"query": "your search query", "top_k": 5}'
```

### Admin Interface
```bash
# Access at http://localhost:8000/admin/
# Username/password: Set with createsuperuser
```

---

## Next Steps (Roadmap)

- [ ] Phase 4: Chat endpoint with LLM integration
- [ ] Phase 5: LangGraph orchestration
- [ ] Phase 6: Streaming responses (SSE)
- [ ] Phase 7: Session memory & summarization
- [ ] Phase 8: Rate limiting, CORS, observability
- [ ] Phase 9: Documentation & deployment

---

## License

MIT
